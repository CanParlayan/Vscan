from urllib.parse import urlparse
from VulnerabilityScanner.src import scanner
from VulnerabilityScanner import Crawler
from VulnerabilityScanner.src.terminalColors import TerminalColors


def singlescan(url, report, payload=None, threads=None):
    threads = threads or 1  
    print(f"{TerminalColors.OKBLUE}Scanning for SQLI{TerminalColors.ENDC}")
    if urlparse(url).query:
        result = scanner.scan([url], threads=threads)  
        if result:
            for vulnerability in result:
                report.write_to_report(vulnerability)
            return result
        else:
            print(f"{TerminalColors.OKGREEN}No SQL injection vulnerability found.{TerminalColors.ENDC}")
            return []

    print(f"{TerminalColors.OKBLUE}Crawling {url}{TerminalColors.ENDC}")
    urls = Crawler.Crawler.deep_crawl(url, 3)

    if not urls:
        print(f"{TerminalColors.WARNING}Found no suitable URLs to test for SQLi.{TerminalColors.ENDC}")
        return []

    print(f"{TerminalColors.OKBLUE}Found {len(urls)} URLs from crawling.{TerminalColors.ENDC}")
    
    payload_dir = payload if payload else "payloads"
    sql_vulns = scanner.scan(urls, payload_dir=payload_dir, threads=threads)  

    if not sql_vulns:
        print(f"{TerminalColors.OKGREEN}No SQL injection vulnerability found.{TerminalColors.ENDC}")
        return []

    for vulnerability in sql_vulns:
        print(f"{TerminalColors.OKBLUE}Writing to report {vulnerability}{TerminalColors.ENDC}")
        report.write_to_report(vulnerability)

    return sql_vulns
